{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 11:34:38.569061: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Dependencies to Visualize the model\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "from IPython.display import Image, SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# Setting seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# Filepaths, pandas, numpy, Tensorflow, and scikit-image\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import skimage as sk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratify Images in Main Image Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read the CSV file\n",
    "csv_file = \"Resources/HAM10000_metadata.csv\"\n",
    "metadata = pd.read_csv(csv_file)\n",
    "\n",
    "# Define the source directory where all the images are located\n",
    "source_dir = \"Resources/Skin Cancer\"\n",
    "\n",
    "# Define the target directories for train and val splits\n",
    "train_dir = \"Resources/Skin Cancer/train\"\n",
    "val_dir = \"Resources/Skin Cancer/val\"\n",
    "\n",
    "# Define the split ratio (e.g., 0.8 for 80% train, 0.2 for 20% val)\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Create the target directories if they don't exist\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "\n",
    "# Get the unique class labels\n",
    "class_labels = metadata[\"dx\"].unique()\n",
    "\n",
    "# Create subdirectories for each class in train and val directories\n",
    "for label in class_labels:\n",
    "    os.makedirs(os.path.join(train_dir, label), exist_ok=True)\n",
    "    os.makedirs(os.path.join(val_dir, label), exist_ok=True)\n",
    "\n",
    "# Split the metadata into train and validation sets using stratified splitting\n",
    "# Stratify was required here to ensure that an 80-20 split occured for all classes in the dataset, not just an 80-20 split of the entire dataset.\n",
    "train_metadata, val_metadata = train_test_split(\n",
    "    metadata, stratify=metadata[\"dx\"], test_size=1 - split_ratio, random_state=42\n",
    ")\n",
    "\n",
    "# Move or copy the images to the respective train and validation directories\n",
    "for _, row in train_metadata.iterrows():\n",
    "    image_id = row[\"image_id\"]\n",
    "    image_path = os.path.join(source_dir, f\"{image_id}.jpg\")\n",
    "    class_label = row[\"dx\"]\n",
    "    target_dir = os.path.join(train_dir, class_label)\n",
    "    shutil.copy(image_path, target_dir)\n",
    "\n",
    "for _, row in val_metadata.iterrows():\n",
    "    image_id = row[\"image_id\"]\n",
    "    image_path = os.path.join(source_dir, f\"{image_id}.jpg\")\n",
    "    class_label = row[\"dx\"]\n",
    "    target_dir = os.path.join(val_dir, class_label)\n",
    "    shutil.copy(image_path, target_dir)\n",
    "\n",
    "print(\"Stratified splitting and image organization completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 images belonging to 7 classes.\n",
      "Found 2003 images belonging to 7 classes.\n",
      "Class Names: ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
      "Train Dataset Shape: (600, 450, 3)\n",
      "Validation Dataset Shape: (600, 450, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the path to your image directory\n",
    "image_directory = \"../Resources/Skin Cancer\"\n",
    "\n",
    "# Defining original image size\n",
    "image_size = (600, 450)\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    " \n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,  # Normalize pixel values\n",
    ")\n",
    "\n",
    "# Load and preprocess the train dataset with data augmentation\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    directory=os.path.join(image_directory, \"train\"),  # Use the 'train' directory\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Create an ImageDataGenerator for validation data (no augmentation)\n",
    "val_datagen = ImageDataGenerator(rescale=1.0 / 255)  # Normalize pixel values\n",
    "\n",
    "# Load and preprocess the validation dataset without data augmentation\n",
    "val_dataset = val_datagen.flow_from_directory(\n",
    "    directory=os.path.join(image_directory, \"val\"),  # Use the 'val' directory\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# Print the class names\n",
    "class_names = list(train_dataset.class_indices.keys())\n",
    "print(\"Class Names:\", class_names)\n",
    "\n",
    "# Print the shape of the datasets\n",
    "print(\"Train Dataset Shape:\", train_dataset.image_shape)\n",
    "print(\"Validation Dataset Shape:\", val_dataset.image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Weight Adjustment\n",
    "This section is to adjust the loss function to more heavily weight our cancerous classes - 'mel', 'akeic', and 'bbc'. This will account for the class imbalance in our original data sets to give us more accurate predictions on the cancerous classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a CSV file to store the model results\n",
    "csv_file = \"model_results.csv\"\n",
    "fieldnames = [\n",
    "    \"architecture\",\n",
    "    \"optimizer\",\n",
    "    \"loss\",\n",
    "    \"accuracy\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"auc\",\n",
    "]\n",
    "\n",
    "# Write the header to the CSV file. Data is written to the file after model_result\n",
    "with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "# Define batch size, architecture, and optimizer\n",
    "batch_size = 32\n",
    "architectures = [\"InceptionV3\"]\n",
    "optimizers = [\"Adam\"]\n",
    "\n",
    "# Create directory to store models\n",
    "models_dir = \"models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Initialize model_results to store the evaluation results\n",
    "model_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 images belonging to 7 classes.\n",
      "Original Class Weights: [ 4.36859324  2.78484532  1.30212904 12.44099379  1.28603531  0.21338021\n",
      " 10.04010025]\n",
      "Original Class Weight Dictionary: {0: 4.368593238822246, 1: 2.7848453249913105, 2: 1.3021290427433772, 3: 12.440993788819876, 4: 1.2860353130016051, 5: 0.21338020666879728, 6: 10.040100250626567}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Initialize an empty dictionary to store the adjusted class weights\n",
    "adjusted_class_weights = {}\n",
    "\n",
    "# Loop through architectures and optimizers\n",
    "for architecture in architectures:\n",
    "    for optimizer_name in optimizers:\n",
    "        # Define the optimizer\n",
    "        if optimizer_name == \"Adam\":\n",
    "            optimizer = Adam(learning_rate=0.001)\n",
    "        elif optimizer_name == \"RMSprop\":\n",
    "            optimizer = RMSprop(learning_rate=0.001)\n",
    "        elif optimizer_name == \"SGD\":\n",
    "            optimizer = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "        # Load and preprocess data using tf.keras.preprocessing\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocessing_function,\n",
    "        )\n",
    "\n",
    "        train_dataset = train_datagen.flow_from_directory(\n",
    "            \"../Resources/Skin Cancer/train\",\n",
    "            target_size=input_shape[:2],\n",
    "            batch_size=batch_size,\n",
    "            class_mode=\"categorical\",\n",
    "        )\n",
    "\n",
    "        # Calculate class weights\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(train_dataset.classes),\n",
    "            y=train_dataset.classes\n",
    "        )\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "        print(\"Original Class Weights:\", class_weights)\n",
    "        print(\"Original Class Weight Dictionary:\", class_weight_dict)\n",
    "\n",
    "        # Define the indices of the classes you want to prioritize\n",
    "        priority_classes = [0,1,4] # Class numbers for 'akeic', 'bcc', and 'mel' respectively\n",
    "\n",
    "        # Define the weight multiplier for the priority classes\n",
    "        priority_weight_multiplier = 5  # Adjust this value as needed\n",
    "\n",
    "        # Assign higher weights to the priority classes and keep the weights for other classes unchanged\n",
    "        for class_num, class_weight in enumerate(class_weights):\n",
    "            if class_num in priority_classes:\n",
    "                if class_num == 4:  # 'mel' is class 4\n",
    "                    class_weight_dict[class_num] = class_weight * priority_weight_multiplier * 4  # Quadrupling the multiplier for 'mel'\n",
    "                else:\n",
    "                    class_weight_dict[class_num] = class_weight * priority_weight_multiplier\n",
    "            else:\n",
    "                class_weight_dict[class_num] = class_weight\n",
    "        \n",
    "        # Add adjusted class weights to the dictionary\n",
    "        adjusted_class_weights.update(class_weight_dict)\n",
    "\n",
    "        # Define the loss function with the manually adjusted class weights\n",
    "        def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "            \"\"\"\n",
    "            Custom loss function for weighted categorical crossentropy.\n",
    "\n",
    "            Args:\n",
    "                y_true (tensor): True labels.\n",
    "                y_pred (tensor): Predicted probabilities.\n",
    "\n",
    "            Returns:\n",
    "                tensor: Weighted categorical crossentropy loss.\n",
    "            \"\"\"\n",
    "\n",
    "            # Define a tensor containing the class weights\n",
    "            weights = tf.constant([adjusted_class_weights[class_num] for class_num in range(num_classes)], dtype=tf.float32)\n",
    "\n",
    "            # Clip predicted probabilities to avoid numerical instability\n",
    "            y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "\n",
    "            # Compute the categorical cross-entropy loss with weighted class probabilities\n",
    "            loss = tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred) * weights, axis=-1))\n",
    "\n",
    "            return loss\n",
    "\n",
    "        # Define the pre-trained model architecture\n",
    "        if architecture == \"VGG16\":\n",
    "            base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "        elif architecture == \"ResNet50\":\n",
    "            base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "        elif architecture == \"InceptionV3\":\n",
    "            base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "\n",
    "        # Freeze the layers of the pre-trained model\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Add custom layers on top of the pre-trained model\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation=\"relu\")(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "        # Create the final model\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "        # Compile the model with the weighted loss function\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=weighted_categorical_crossentropy,\n",
    "            metrics=[\"accuracy\", Precision(), Recall(), AUC()],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Class Weights:\n",
      "0: 21.84296619411123\n",
      "1: 13.924226624956553\n",
      "2: 1.3021290427433772\n",
      "3: 12.440993788819876\n",
      "4: 25.720706260032102\n",
      "5: 0.21338020666879728\n",
      "6: 10.040100250626567\n",
      "{0: 21.84296619411123, 1: 13.924226624956553, 2: 1.3021290427433772, 3: 12.440993788819876, 4: 25.720706260032102, 5: 0.21338020666879728, 6: 10.040100250626567}\n"
     ]
    }
   ],
   "source": [
    "# Print adjusted class weights\n",
    "print(\"Adjusted Class Weights:\")\n",
    "for class_num, class_weight in adjusted_class_weights.items():\n",
    "    print(f\"{class_num}: {class_weight}\")\n",
    "\n",
    "#Print adjusted class weights dictionary\n",
    "print(adjusted_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-step Model Building\n",
    "This section contains a cell-by-cell break down of the model creation, and allows for the testing of singular models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "import os\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an Architecture\n",
    "architecture = \"InceptionV3\"  # Options: \"VGG16\", \"ResNet50\", \"InceptionV3\"\n",
    "\n",
    "# Set the input shape and preprocessing function based on the selected architecture\n",
    "if architecture == \"VGG16\":\n",
    "    input_shape = (224, 224, 3)\n",
    "    preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n",
    "if architecture == \"resnet50\":\n",
    "    input_shape = (224, 224, 3)\n",
    "    preprocessing_function = tf.keras.applications.resnet.preprocess_input\n",
    "elif architecture == \"InceptionV3\":\n",
    "    input_shape = (299, 299, 3)\n",
    "    preprocessing_function = tf.keras.applications.inception_v3.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data using tf.keras.preprocessing\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocessing_function,\n",
    "    # rotation_range=20,\n",
    "    # width_shift_range=0.2,\n",
    "    # height_shift_range=0.2,\n",
    "    # horizontal_flip=True,\n",
    ")\n",
    "\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    \"Resources/Skin Cancer/train\",\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
    "\n",
    "val_dataset = val_datagen.flow_from_directory(\n",
    "    \"Resources/Skin Cancer/val\",\n",
    "    target_size=input_shape[:2],\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pre-trained model architecture\n",
    "if architecture == \"VGG16\":\n",
    "    base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "elif architecture == \"ResNet50\":\n",
    "    base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "elif architecture == \"InceptionV3\":\n",
    "    base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Layering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of unique classes from the train_dataset\n",
    "num_classes = len(train_dataset.class_indices)\n",
    "\n",
    "# Add custom layers on top of the pre-trained model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation=\"relu\")(x)\n",
    "x = Dropout(0.5)(x)\n",
    "num_classes = len(train_dataset.class_indices)\n",
    "predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose an Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an Optimizer\n",
    "optimizer_name = \"Adam\"  # Options: \"Adam\", \"RMSprop\", \"SGD\"\n",
    "\n",
    "if optimizer_name == \"Adam\":\n",
    "    optimizer = Adam(learning_rate=0.001)\n",
    "elif optimizer_name == \"RMSprop\":\n",
    "    optimizer = RMSprop(learning_rate=0.001)\n",
    "elif optimizer_name == \"SGD\":\n",
    "    optimizer = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.1, patience=5, verbose=1)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\", Precision(), Recall(), AUC()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Callbacks for TensorBoard and CSV tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create callbacks\n",
    "tensorboard_callback = TensorBoard(log_dir=f\"./logs/{architecture}_{optimizer_name}\", histogram_freq=1)\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=f\"models/model_{architecture}_{optimizer_name}.weights.h5\",\n",
    "    save_weights_only=True,\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_loss\",\n",
    "    verbose=1,\n",
    ")\n",
    "csv_logger = CSVLogger(f\"models/model_{architecture}_{optimizer_name}_training.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with callbacks\n",
    "epochs = 10\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=train_dataset.samples // 32,\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=val_dataset.samples // 32,\n",
    "    epochs=epochs,\n",
    "    callbacks=[tensorboard_callback, lr_scheduler, checkpoint_callback, csv_logger],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set and print the results\n",
    "loss, accuracy, precision, recall, auc = model.evaluate(val_dataset)\n",
    "print(f\"Model: {architecture}, Optimizer: {optimizer_name}\")\n",
    "print(f\"Validation Loss: {loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {precision:.4f}\")\n",
    "print(f\"Validation Recall: {recall:.4f}\")\n",
    "print(f\"Validation AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "model.save(f\"models/model_{architecture}_{optimizer_name}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Testing \n",
    "This section contains a conglomerated model run. It was created so that the models could be tested overnight. I'm going to bed now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 images belonging to 7 classes.\n",
      "Found 2003 images belonging to 7 classes.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 13:24:40.677304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 35.1192 - accuracy: 0.1189 - precision_8: 0.1307 - recall_8: 0.0940 - auc_8: 0.4999"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 13:33:40.930077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 4.84906, saving model to run7/models/model_InceptionV3_Adam.weights.h5\n",
      "250/250 [==============================] - 679s 3s/step - loss: 35.1192 - accuracy: 0.1189 - precision_8: 0.1307 - recall_8: 0.0940 - auc_8: 0.4999 - val_loss: 4.8491 - val_accuracy: 0.1265 - val_precision_8: 0.1371 - val_recall_8: 0.0948 - val_auc_8: 0.6237 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 25.0361 - accuracy: 0.1511 - precision_8: 0.1568 - recall_8: 0.1059 - auc_8: 0.6103\n",
      "Epoch 2: val_loss improved from 4.84906 to 4.61738, saving model to run7/models/model_InceptionV3_Adam.weights.h5\n",
      "250/250 [==============================] - 688s 3s/step - loss: 25.0361 - accuracy: 0.1511 - precision_8: 0.1568 - recall_8: 0.1059 - auc_8: 0.6103 - val_loss: 4.6174 - val_accuracy: 0.1386 - val_precision_8: 0.1451 - val_recall_8: 0.1200 - val_auc_8: 0.5983 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 23.8224 - accuracy: 0.1683 - precision_8: 0.1785 - recall_8: 0.1253 - auc_8: 0.6337\n",
      "Epoch 3: val_loss improved from 4.61738 to 4.57366, saving model to run7/models/model_InceptionV3_Adam.weights.h5\n",
      "250/250 [==============================] - 652s 3s/step - loss: 23.8224 - accuracy: 0.1683 - precision_8: 0.1785 - recall_8: 0.1253 - auc_8: 0.6337 - val_loss: 4.5737 - val_accuracy: 0.1820 - val_precision_8: 0.1625 - val_recall_8: 0.1290 - val_auc_8: 0.7154 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 22.5101 - accuracy: 0.2193 - precision_8: 0.2213 - recall_8: 0.1574 - auc_8: 0.6770\n",
      "Epoch 4: val_loss improved from 4.57366 to 4.38526, saving model to run7/models/model_InceptionV3_Adam.weights.h5\n",
      "250/250 [==============================] - 647s 3s/step - loss: 22.5101 - accuracy: 0.2193 - precision_8: 0.2213 - recall_8: 0.1574 - auc_8: 0.6770 - val_loss: 4.3853 - val_accuracy: 0.1915 - val_precision_8: 0.1998 - val_recall_8: 0.1124 - val_auc_8: 0.6589 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 21.6120 - accuracy: 0.2167 - precision_8: 0.2251 - recall_8: 0.1629 - auc_8: 0.6763\n",
      "Epoch 5: val_loss did not improve from 4.38526\n",
      "250/250 [==============================] - 651s 3s/step - loss: 21.6120 - accuracy: 0.2167 - precision_8: 0.2251 - recall_8: 0.1629 - auc_8: 0.6763 - val_loss: 4.3938 - val_accuracy: 0.1618 - val_precision_8: 0.1589 - val_recall_8: 0.1290 - val_auc_8: 0.7049 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.9158 - accuracy: 0.2201 - precision_8: 0.2256 - recall_8: 0.1683 - auc_8: 0.6861\n",
      "Epoch 6: val_loss did not improve from 4.38526\n",
      "250/250 [==============================] - 640s 3s/step - loss: 20.9158 - accuracy: 0.2201 - precision_8: 0.2256 - recall_8: 0.1683 - auc_8: 0.6861 - val_loss: 4.4221 - val_accuracy: 0.2404 - val_precision_8: 0.2432 - val_recall_8: 0.1447 - val_auc_8: 0.7023 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 20.8101 - accuracy: 0.2470 - precision_8: 0.2546 - recall_8: 0.1888 - auc_8: 0.7035\n",
      "Epoch 7: val_loss improved from 4.38526 to 4.07376, saving model to run7/models/model_InceptionV3_Adam.weights.h5\n",
      "250/250 [==============================] - 637s 3s/step - loss: 20.8101 - accuracy: 0.2470 - precision_8: 0.2546 - recall_8: 0.1888 - auc_8: 0.7035 - val_loss: 4.0738 - val_accuracy: 0.2727 - val_precision_8: 0.2654 - val_recall_8: 0.1981 - val_auc_8: 0.7427 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 19.3323 - accuracy: 0.2586 - precision_8: 0.2699 - recall_8: 0.2029 - auc_8: 0.7089\n",
      "Epoch 8: val_loss did not improve from 4.07376\n",
      "250/250 [==============================] - 625s 3s/step - loss: 19.3323 - accuracy: 0.2586 - precision_8: 0.2699 - recall_8: 0.2029 - auc_8: 0.7089 - val_loss: 4.6708 - val_accuracy: 0.2182 - val_precision_8: 0.2002 - val_recall_8: 0.1689 - val_auc_8: 0.7223 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 19.7044 - accuracy: 0.2446 - precision_8: 0.2592 - recall_8: 0.1922 - auc_8: 0.7065\n",
      "Epoch 9: val_loss improved from 4.07376 to 3.95957, saving model to run7/models/model_InceptionV3_Adam.weights.h5\n",
      "250/250 [==============================] - 626s 3s/step - loss: 19.7044 - accuracy: 0.2446 - precision_8: 0.2592 - recall_8: 0.1922 - auc_8: 0.7065 - val_loss: 3.9596 - val_accuracy: 0.2268 - val_precision_8: 0.2292 - val_recall_8: 0.1678 - val_auc_8: 0.6887 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - ETA: 0s - loss: 18.5788 - accuracy: 0.2320 - precision_8: 0.2439 - recall_8: 0.1891 - auc_8: 0.7148\n",
      "Epoch 10: val_loss did not improve from 3.95957\n",
      "250/250 [==============================] - 628s 3s/step - loss: 18.5788 - accuracy: 0.2320 - precision_8: 0.2439 - recall_8: 0.1891 - auc_8: 0.7148 - val_loss: 4.0380 - val_accuracy: 0.2762 - val_precision_8: 0.2651 - val_recall_8: 0.2016 - val_auc_8: 0.7653 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 15:12:35.685121: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 121s 2s/step - loss: 4.0313 - accuracy: 0.2771 - precision_8: 0.2657 - recall_8: 0.2022 - auc_8: 0.7654\n",
      "Model: InceptionV3, Optimizer: Adam\n",
      "Validation Loss: 4.0313\n",
      "Validation Accuracy: 0.2771\n",
      "Validation Precision: 0.2657\n",
      "Validation Recall: 0.2022\n",
      "Validation AUC-ROC: 0.7654\n"
     ]
    }
   ],
   "source": [
    "# Importing Dependencies\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Run Number - use to create new directory or add to existing directory\n",
    "run_number = 7\n",
    "run_dir = f\"run{run_number}\"\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "# Creating a CSV file to store the model results\n",
    "csv_file = \"model_results.csv\"\n",
    "fieldnames = [\n",
    "    \"architecture\",\n",
    "    \"optimizer\",\n",
    "    \"loss\",\n",
    "    \"accuracy\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"auc\",\n",
    "]\n",
    "\n",
    "# Write the header to the CSV file. Data is written to the file after model_result\n",
    "with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "batch_size = 32\n",
    "architectures = [\"InceptionV3\"] # Options: \"VGG16\", \"ResNet50\", \"InceptionV3\"\n",
    "optimizers = [\"Adam\"] # Options: \"Adam\", \"RMSprop\", \"SGD\"\n",
    "\n",
    "# Create directory to store models\n",
    "models_dir = f\"{run_dir}/models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Initialize model_results to store the evaluation results\n",
    "model_results = []\n",
    "\n",
    "for architecture in architectures:\n",
    "    # Set the input shape and preprocessing function based on the selected architecture\n",
    "    if architecture == \"VGG16\" or architecture == \"ResNet50\":\n",
    "        input_shape = (224, 224, 3)\n",
    "        preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n",
    "    elif architecture == \"ResNet50\":\n",
    "        input_shape = (224, 224, 3)\n",
    "        preprocessing_function = tf.keras.applications.resnet50.preprocess_input\n",
    "    elif architecture == \"InceptionV3\":\n",
    "        input_shape = (299, 299, 3)\n",
    "        preprocessing_function = tf.keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    # Load and preprocess data using tf.keras.preprocessing\n",
    "    # This adds data augmentation to the training dataset\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocessing_function,\n",
    "    )\n",
    "\n",
    "    train_dataset = train_datagen.flow_from_directory(\n",
    "        \"../Resources/Skin Cancer/train\",\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "    )\n",
    "\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
    "\n",
    "    # Define the validation dataset without data augmentation\n",
    "    val_dataset = val_datagen.flow_from_directory(\n",
    "        \"../Resources/Skin Cancer/val\",\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "    )\n",
    "\n",
    "    # Define the pre-trained model architecture. Will select proper model based on current 'architecture' in for loop\n",
    "    if architecture == \"VGG16\":\n",
    "        base_model = VGG16(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=input_shape\n",
    "        )\n",
    "    elif architecture == \"ResNet50\":\n",
    "        base_model = ResNet50(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=input_shape\n",
    "        )\n",
    "    elif architecture == \"InceptionV3\":\n",
    "        base_model = InceptionV3(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=input_shape\n",
    "        )\n",
    "\n",
    "    # Freeze the layers of the pre-trained model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Get the number of unique classes from the train_dataset\n",
    "    num_classes = len(train_dataset.class_indices)\n",
    "\n",
    "    # Add custom layers on top of the pre-trained model\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # Create the final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Step through and adjust for each optimizer\n",
    "    for optimizer_name in optimizers:\n",
    "        # Define the optimizer\n",
    "        if optimizer_name == \"Adam\":\n",
    "            optimizer = Adam(learning_rate=0.001)\n",
    "        elif optimizer_name == \"RMSprop\":\n",
    "            optimizer = RMSprop(learning_rate=0.001)\n",
    "        elif optimizer_name == \"SGD\":\n",
    "            optimizer = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "        # Create learning rate scheduler that monitors validation loss\n",
    "        lr_scheduler = ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.1, patience=5, verbose=1\n",
    "        )\n",
    "\n",
    "        # Compile the model with the weighted loss function\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=weighted_categorical_crossentropy,  # Use the custom loss function\n",
    "            metrics=[\"accuracy\", Precision(), Recall(), AUC()],\n",
    "        )\n",
    "\n",
    "        # Create a TensorBoard callback with a separate log directory for each model and optimizer\n",
    "        tensorboard_callback = TensorBoard(\n",
    "            log_dir=f\"./{run_dir}/logs/{architecture}_{optimizer_name}\", histogram_freq=1\n",
    "        )\n",
    "\n",
    "        # Create an EarlyStopping callback to prevent overfitting\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        # Create a ModelCheckpoint callback to save the best model weights\n",
    "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(\n",
    "                models_dir, f\"model_{architecture}_{optimizer_name}.weights.h5\"\n",
    "            ),\n",
    "            save_weights_only=True,\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\",\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        # Create a CSVLogger callback with keras\n",
    "        csv_logger = CSVLogger(\n",
    "            os.path.join(\n",
    "                models_dir, f\"model_{architecture}_{optimizer_name}_training.csv\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # IMPORTANT: RESEARACH CLASS WEIGHTING\n",
    "        # Calculate class weights\n",
    "        # This step is required, as some of the classes are imbalanced, in particular, the val classes\n",
    "        # class_weights = class_weight.compute_class_weight(\n",
    "        #     'balanced',\n",
    "        #     classes=np.unique(train_dataset.classes),\n",
    "        #     y=train_dataset.classes\n",
    "        # )\n",
    "        # class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "        # Train the model with the checkpoint callback and weights\n",
    "        epochs = 10\n",
    "        history = model.fit(\n",
    "            train_dataset,\n",
    "            steps_per_epoch=train_dataset.samples // batch_size,\n",
    "            validation_data=val_dataset,\n",
    "            validation_steps=val_dataset.samples // batch_size,\n",
    "            epochs=epochs,\n",
    "            class_weight=adjusted_class_weights,\n",
    "            callbacks=[tensorboard_callback, lr_scheduler, checkpoint_callback, csv_logger],\n",
    "        )\n",
    "\n",
    "        # Save the optimizer state to avoid retraining the model\n",
    "        model.save(\n",
    "            os.path.join(models_dir, f\"model_{architecture}_{optimizer_name}.h5\")\n",
    "        )\n",
    "\n",
    "        # Evaluate the model on the validation set and print the results\n",
    "        loss, accuracy, precision, recall, auc = model.evaluate(val_dataset)\n",
    "        print(f\"Model: {architecture}, Optimizer: {optimizer_name}\")\n",
    "        print(f\"Validation Loss: {loss:.4f}\")\n",
    "        print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Validation Precision: {precision:.4f}\")\n",
    "        print(f\"Validation Recall: {recall:.4f}\")\n",
    "        print(f\"Validation AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "        # Append the model results to the list\n",
    "        model_result = {\n",
    "            \"architecture\": architecture,\n",
    "            \"optimizer\": optimizer_name,\n",
    "            \"loss\": loss,\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"auc\": auc,\n",
    "        }\n",
    "        model_results.append(model_result)\n",
    "\n",
    "        # Write the current model result to the CSV file\n",
    "        with open(csv_file, mode=\"a\", newline=\"\") as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            writer.writerow(model_result)\n",
    "\n",
    "        # Save the model\n",
    "        model.save(\n",
    "            os.path.join(models_dir, f\"model_{architecture}_{optimizer_name}.h5\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted Class Weights:\n",
      "0: 21.84296619411123\n",
      "1: 13.924226624956553\n",
      "2: 1.3021290427433772\n",
      "3: 12.440993788819876\n",
      "4: 25.720706260032102\n",
      "5: 0.21338020666879728\n",
      "6: 10.040100250626567\n",
      "{0: 21.84296619411123, 1: 13.924226624956553, 2: 1.3021290427433772, 3: 12.440993788819876, 4: 25.720706260032102, 5: 0.21338020666879728, 6: 10.040100250626567}\n"
     ]
    }
   ],
   "source": [
    "# Print adjusted class weights\n",
    "print(\"Adjusted Class Weights:\")\n",
    "for class_num, class_weight in adjusted_class_weights.items():\n",
    "    print(f\"{class_num}: {class_weight}\")\n",
    "\n",
    "#Print adjusted class weights dictionary\n",
    "print(adjusted_class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Weight Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 images belonging to 7 classes.\n",
      "Found 2003 images belonging to 7 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 26s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Importing Dependencies\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Creating a CSV file to store the model results\n",
    "csv_file = \"model_results.csv\"\n",
    "fieldnames = [\n",
    "    \"architecture\",\n",
    "    \"optimizer\",\n",
    "    \"loss\",\n",
    "    \"accuracy\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"auc\",\n",
    "]\n",
    "\n",
    "# Write the header to the CSV file. Data is written to the file after model_result\n",
    "with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "batch_size = 32\n",
    "architectures = [\"InceptionV3\"]\n",
    "optimizers = [\"Adam\"]\n",
    "\n",
    "# Create directory to store models\n",
    "models_dir = \"models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Initialize model_results to store the evaluation results\n",
    "model_results = []\n",
    "\n",
    "for architecture in architectures:\n",
    "    # Set the input shape and preprocessing function based on the selected architecture\n",
    "    if architecture == \"VGG16\" or architecture == \"ResNet50\":\n",
    "        input_shape = (224, 224, 3)\n",
    "        preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n",
    "    elif architecture == \"InceptionV3\":\n",
    "        input_shape = (299, 299, 3)\n",
    "        preprocessing_function = tf.keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    # Load and preprocess data using tf.keras.preprocessing\n",
    "    # This is add data augmentation to the training dataset\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocessing_function,\n",
    "        # rotation_range=20,\n",
    "        # width_shift_range=0.2,\n",
    "        # height_shift_range=0.2,\n",
    "        # horizontal_flip=True,\n",
    "    )\n",
    "\n",
    "    train_dataset = train_datagen.flow_from_directory(\n",
    "        \"Resources/Skin Cancer/train\",\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "    )\n",
    "\n",
    "    \n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
    "\n",
    "    # Define the validation dataset without data augmentation\n",
    "    val_dataset = val_datagen.flow_from_directory(\n",
    "        \"Resources/Skin Cancer/val\",\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "    )\n",
    "\n",
    "    # Define the pre-trained model architecture. Will select proper model based on current 'architecture' in for loop\n",
    "    if architecture == \"VGG16\":\n",
    "        base_model = VGG16(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=input_shape\n",
    "        )\n",
    "    elif architecture == \"ResNet50\":\n",
    "        base_model = ResNet50(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=input_shape\n",
    "        )\n",
    "    elif architecture == \"InceptionV3\":\n",
    "        base_model = InceptionV3(\n",
    "            weights=\"imagenet\", include_top=False, input_shape=input_shape\n",
    "        )\n",
    "\n",
    "    # Freeze the layers of the pre-trained model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Get the number of unique classes from the train_dataset\n",
    "    num_classes = len(train_dataset.class_indices)\n",
    "\n",
    "    # Add custom layers on top of the pre-trained model\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # Create the final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # Step through and adjust for each optimizer\n",
    "    for optimizer_name in optimizers:\n",
    "        # Define the optimizer\n",
    "        # Learning rate is the size of the step the optimizer will take to minimize the loss function\n",
    "        if optimizer_name == \"Adam\":\n",
    "            optimizer = Adam(learning_rate=0.001)\n",
    "        elif optimizer_name == \"RMSprop\":\n",
    "            optimizer = RMSprop(learning_rate=0.001)\n",
    "        elif optimizer_name == \"SGD\":\n",
    "            optimizer = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "        # Create learning rate scheduler that monitors validation loss\n",
    "        lr_scheduler = ReduceLROnPlateau(\n",
    "            monitor=\"val_loss\", factor=0.1, patience=5, verbose=1\n",
    "        )\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=\"categorical_crossentropy\",\n",
    "            metrics=[\"accuracy\", Precision(), Recall(), AUC()],\n",
    "        )\n",
    "\n",
    "        # Create a TensorBoard callback with a separate log directory for each model and optimizer\n",
    "        tensorboard_callback = TensorBoard(\n",
    "            log_dir=f\"./logs/{architecture}_{optimizer_name}\", histogram_freq=1\n",
    "        )\n",
    "\n",
    "        # Create an EarlyStopping callback to prevent overfitting\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    "        )\n",
    "\n",
    "        # Create a ModelCheckpoint callback to save the best model weights\n",
    "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(\n",
    "                models_dir, f\"model_{architecture}_{optimizer_name}.weights.h5\"\n",
    "            ),\n",
    "            save_weights_only=True,\n",
    "            save_best_only=True,\n",
    "            monitor=\"val_loss\",\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        # Create a CSVLogger callback with keras\n",
    "        csv_logger = CSVLogger(\n",
    "            os.path.join(\n",
    "                models_dir, f\"model_{architecture}_{optimizer_name}_training.csv\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Calculate class weights\n",
    "        # This step is required, as some of the classes are imbalanced, in particular, the val classes\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            'balanced',\n",
    "            classes=np.unique(train_dataset.classes),\n",
    "            y=train_dataset.classes\n",
    "        )\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.36859324  2.78484532  1.30212904 12.44099379  1.28603531  0.21338021\n",
      " 10.04010025]\n",
      "{0: 4.368593238822246, 1: 2.7848453249913105, 2: 1.3021290427433772, 3: 12.440993788819876, 4: 1.2860353130016051, 5: 0.21338020666879728, 6: 10.040100250626567}\n",
      "akiec: 4.368593238822246\n",
      "bcc: 2.7848453249913105\n",
      "bkl: 1.3021290427433772\n",
      "df: 12.440993788819876\n",
      "mel: 1.2860353130016051\n",
      "nv: 0.21338020666879728\n",
      "vasc: 10.040100250626567\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)\n",
    "print(class_weight_dict)\n",
    "\n",
    "for class_name, class_weight in zip(class_names, class_weights):\n",
    "    print(f\"{class_name}: {class_weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with adjusting the loss function for 'akiec', 'bcc', and 'mel' to address class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a CSV file to store the model results\n",
    "csv_file = \"model_results.csv\"\n",
    "fieldnames = [\n",
    "    \"architecture\",\n",
    "    \"optimizer\",\n",
    "    \"loss\",\n",
    "    \"accuracy\",\n",
    "    \"precision\",\n",
    "    \"recall\",\n",
    "    \"auc\",\n",
    "]\n",
    "\n",
    "# Write the header to the CSV file. Data is written to the file after model_result\n",
    "with open(csv_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "# Define batch size, architecture, and optimizer\n",
    "batch_size = 32\n",
    "architectures = [\"InceptionV3\"]\n",
    "optimizers = [\"Adam\"]\n",
    "\n",
    "# Create directory to store models\n",
    "models_dir = \"models\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Initialize model_results to store the evaluation results\n",
    "model_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 images belonging to 7 classes.\n",
      "Class Weights: [ 4.36859324  2.78484532  1.30212904 12.44099379  1.28603531  0.21338021\n",
      " 10.04010025]\n",
      "Class Weight Dictionary: {0: 4.368593238822246, 1: 2.7848453249913105, 2: 1.3021290427433772, 3: 12.440993788819876, 4: 1.2860353130016051, 5: 0.21338020666879728, 6: 10.040100250626567}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Loop through architectures and optimizers\n",
    "for architecture in architectures:\n",
    "    for optimizer_name in optimizers:\n",
    "        # Define the optimizer\n",
    "        if optimizer_name == \"Adam\":\n",
    "            optimizer = Adam(learning_rate=0.001)\n",
    "        elif optimizer_name == \"RMSprop\":\n",
    "            optimizer = RMSprop(learning_rate=0.001)\n",
    "        elif optimizer_name == \"SGD\":\n",
    "            optimizer = SGD(learning_rate=0.001, momentum=0.9)\n",
    "\n",
    "        # Load and preprocess data using tf.keras.preprocessing\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocessing_function,\n",
    "        )\n",
    "\n",
    "        train_dataset = train_datagen.flow_from_directory(\n",
    "            \"Resources/Skin Cancer/train\",\n",
    "            target_size=input_shape[:2],\n",
    "            batch_size=batch_size,\n",
    "            class_mode=\"categorical\",\n",
    "        )\n",
    "\n",
    "        # Calculate class weights\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(train_dataset.classes),\n",
    "            y=train_dataset.classes\n",
    "        )\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "        print(\"Class Weights:\", class_weights)\n",
    "        print(\"Class Weight Dictionary:\", class_weight_dict)\n",
    "\n",
    "        # Define the indices of the classes you want to prioritize\n",
    "        priority_classes = ['mel', 'bcc', 'akiec']\n",
    "\n",
    "        # Define the weight multiplier for the priority classes\n",
    "        priority_weight_multiplier = 5  # Adjust this value as needed\n",
    "\n",
    "        # Assign higher weights to the priority classes and keep the weights for other classes unchanged\n",
    "        for class_name, class_weight in zip(class_names, class_weights):\n",
    "            if class_name in priority_classes:\n",
    "                if class_name == 'mel':\n",
    "                    class_weight_dict[class_name] = class_weight * priority_weight_multiplier * 4  # Quadrulpling the multiplier for 'mel'\n",
    "                else:\n",
    "                    class_weight_dict[class_name] = class_weight * priority_weight_multiplier\n",
    "            else:\n",
    "                class_weight_dict[class_name] = class_weight\n",
    "\n",
    "        # Define the loss function with the manually adjusted class weights\n",
    "        def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "            \"\"\"\n",
    "            Custom loss function for weighted categorical crossentropy.\n",
    "\n",
    "            Args:\n",
    "                y_true (tensor): True labels.\n",
    "                y_pred (tensor): Predicted probabilities.\n",
    "\n",
    "            Returns:\n",
    "                tensor: Weighted categorical crossentropy loss.\n",
    "            \"\"\"\n",
    "\n",
    "            # Define a tensor containing the class weights\n",
    "            weights = tf.constant([class_weight_dict[class_name] for class_name in class_names], dtype=tf.float32)\n",
    "\n",
    "            # Clip predicted probabilities to avoid numerical instability\n",
    "            y_pred = tf.clip_by_value(y_pred, tf.keras.backend.epsilon(), 1 - tf.keras.backend.epsilon())\n",
    "\n",
    "            # Compute the categorical cross-entropy loss with weighted class probabilities\n",
    "            loss = tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred) * weights, axis=-1))\n",
    "\n",
    "            return loss\n",
    "\n",
    "        # Define the pre-trained model architecture\n",
    "        if architecture == \"VGG16\":\n",
    "            base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "        elif architecture == \"ResNet50\":\n",
    "            base_model = ResNet50(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "        elif architecture == \"InceptionV3\":\n",
    "            base_model = InceptionV3(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "\n",
    "        # Freeze the layers of the pre-trained model\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Add custom layers on top of the pre-trained model\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation=\"relu\")(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        predictions = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "        # Create the final model\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "        # Compile the model with the weighted loss function\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss=weighted_categorical_crossentropy,\n",
    "            metrics=[\"accuracy\", Precision(), Recall(), AUC()],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "akiec: 4.368593238822246\n",
      "bcc: 2.7848453249913105\n",
      "bkl: 1.3021290427433772\n",
      "df: 12.440993788819876\n",
      "mel: 1.2860353130016051\n",
      "nv: 0.21338020666879728\n",
      "vasc: 10.040100250626567\n"
     ]
    }
   ],
   "source": [
    "# Print original class weights\n",
    "for class_name, class_weight in zip(class_names, class_weights):\n",
    "    print(f\"{class_name}: {class_weight}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 4.368593238822246\n",
      "1: 2.7848453249913105\n",
      "2: 1.3021290427433772\n",
      "3: 12.440993788819876\n",
      "4: 1.2860353130016051\n",
      "5: 0.21338020666879728\n",
      "6: 10.040100250626567\n",
      "akiec: 21.84296619411123\n",
      "bcc: 13.924226624956553\n",
      "bkl: 1.3021290427433772\n",
      "df: 12.440993788819876\n",
      "mel: 25.720706260032102\n",
      "nv: 0.21338020666879728\n",
      "vasc: 10.040100250626567\n"
     ]
    }
   ],
   "source": [
    "# Print adjusted class weights\n",
    "for class_name, class_weight in class_weight_dict.items():\n",
    "    print(f\"{class_name}: {class_weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume from Interrupt \n",
    "Should the overnight run need to be interupted, it is possible to pick up where the interruption left off, and continue training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model architecture and optimizer\n",
    "architecture = \"VGG16\"  # Specify the architecture you want to resume training for\n",
    "optimizer_name = \"Adam\"  # Specify the optimizer you want to resume training with\n",
    "\n",
    "# Load the model \n",
    "model = load_model(os.path.join(models_dir, f\"model_{architecture}_{optimizer_name}.h5\"))\n",
    "\n",
    "# Load the optimizer state\n",
    "with open(os.path.join(models_dir, f\"model_{architecture}_{optimizer_name}_optimizer_state.pkl\"), 'rb') as f:\n",
    "    optimizer_weights = model.load(f)\n",
    "    model.optimizer.set_weights(optimizer_weights)\n",
    "\n",
    "# Resume training from a specific epoch\n",
    "resume_epoch = 5  # Specify the epoch number to resume from\n",
    "for epoch in range(resume_epoch, epochs):\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=train_dataset.samples // 32,\n",
    "        validation_data=val_dataset,\n",
    "        validation_steps=val_dataset.samples // 32,\n",
    "        epochs=1,\n",
    "        callbacks=[tensorboard_callback, lr_scheduler, checkpoint_callback],\n",
    "        initial_epoch=epoch\n",
    "    )\n",
    "\n",
    "    # Save the optimizer state\n",
    "    with open(os.path.join(models_dir, f\"model_{architecture}_{optimizer_name}_optimizer_state.pkl\"), 'wb') as f:\n",
    "        model.dump(model.optimizer.get_weights(), f)\n",
    "\n",
    "     # Save the optimizer state\n",
    "    with open(\n",
    "                os.path.join(\n",
    "                    models_dir,\n",
    "                    f\"model_{architecture}_{optimizer_name}_optimizer_state.pkl\",\n",
    "                ),\n",
    "                \"wb\",\n",
    "            ) as f:\n",
    "                model.dump(model.optimizer.get_weights(), f)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        loss, accuracy, precision, recall, auc = model.evaluate(val_dataset)\n",
    "        print(f\"Model: {architecture}, Optimizer: {optimizer_name}\")\n",
    "        print(f\"Validation Loss: {loss:.4f}\")\n",
    "        print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Validation Precision: {precision:.4f}\")\n",
    "        print(f\"Validation Recall: {recall:.4f}\")\n",
    "        print(f\"Validation AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "        # Append the model results to the list\n",
    "        model_results.append(\n",
    "            {\n",
    "                \"architecture\": architecture,\n",
    "                \"optimizer\": optimizer_name,\n",
    "                \"loss\": loss,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"auc\": auc,\n",
    "            }\n",
    "        )\n",
    "        # Save the model\n",
    "        model.save(\n",
    "            os.path.join(models_dir, f\"model_{architecture}_{optimizer_name}.h5\")\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating and Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2003 images belonging to 7 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown loss function: 'weighted_categorical_crossentropy'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 82\u001b[0m\n\u001b[1;32m     77\u001b[0m class_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(val_dataset\u001b[38;5;241m.\u001b[39mclass_indices\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m optimizer_name \u001b[38;5;129;01min\u001b[39;00m optimizers:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/model_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43marchitecture\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43moptimizer_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# Make predictions on the validation dataset using the redefined val_dataset\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(val_dataset)\n",
      "File \u001b[0;32m~/anaconda3/envs/nn/lib/python3.8/site-packages/keras/saving/saving_api.py:212\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    205\u001b[0m         filepath,\n\u001b[1;32m    206\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    208\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    209\u001b[0m     )\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nn/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/nn/lib/python3.8/site-packages/keras/saving/legacy/serialization.py:543\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    541\u001b[0m     obj \u001b[38;5;241m=\u001b[39m module_objects\u001b[38;5;241m.\u001b[39mget(object_name)\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 543\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    544\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprintable_module_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobject_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    545\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure you are using a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    546\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`keras.utils.custom_object_scope` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand that this object is included in the scope. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    548\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.tensorflow.org/guide/keras/save_and_serialize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    549\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#registering_the_custom_object for details.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    550\u001b[0m         )\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# Classes passed by name are instantiated with no args, functions are\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;66;03m# returned as-is.\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf_inspect\u001b[38;5;241m.\u001b[39misclass(obj):\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown loss function: 'weighted_categorical_crossentropy'. Please ensure you are using a `keras.utils.custom_object_scope` and that this object is included in the scope. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "# Importing Dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "model_results = \"model_results.csv\"\n",
    "\n",
    "# Run Number - use to create new directory or add to existing directory\n",
    "run_number = 7\n",
    "run_dir = f\"run{run_number}\"\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "architectures = [\"InceptionV3\"] \n",
    "optimizers = [\"Adam\"]\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Define the preprocessing function based on the architectures you want to visualize\n",
    "architectures_to_visualize = [\"InceptionV3\"]  # Specify the architectures you want to visualize\n",
    "preprocessing_functions = {\n",
    "    \"VGG16\": tf.keras.applications.vgg16.preprocess_input,\n",
    "    \"ResNet50\": tf.keras.applications.resnet50.preprocess_input,\n",
    "    \"InceptionV3\": tf.keras.applications.inception_v3.preprocess_input\n",
    "}\n",
    "\n",
    "\n",
    "# Create a directory to store the visualization results\n",
    "visualizations_dir = f\"{run_dir}/visualizations\"\n",
    "os.makedirs(visualizations_dir, exist_ok=True)\n",
    "\n",
    "#\n",
    "\n",
    "# Iterate over each model architecture and optimizer\n",
    "for architecture in architectures:\n",
    "    # Set the preprocessing function based on the architecture\n",
    "    preprocessing_function = preprocessing_functions[architecture]\n",
    "\n",
    "    # Set the input shape and preprocessing function based on the selected architecture\n",
    "    if architecture == \"VGG16\":\n",
    "        input_shape = (224, 224, 3)\n",
    "        preprocessing_function = tf.keras.applications.vgg16.preprocess_input\n",
    "    if architecture == \"ResNet50\":\n",
    "        input_shape = (224, 224, 3)\n",
    "        preprocessing_function = tf.keras.applications.resnet50.preprocess_input\n",
    "    elif architecture == \"InceptionV3\":\n",
    "        input_shape = (299, 299, 3)\n",
    "        preprocessing_function = tf.keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    # Redefine the validation dataset with the corresponding preprocessing function\n",
    "    val_datagen = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
    "    val_dataset = val_datagen.flow_from_directory(\n",
    "        \"../Resources/Skin Cancer/val\",\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=batch_size,\n",
    "        class_mode=\"categorical\",\n",
    "    )\n",
    "\n",
    "    # Get the class names from the redefined val_dataset\n",
    "    class_names = list(val_dataset.class_indices.keys())\n",
    "\n",
    "\n",
    "    for optimizer_name in optimizers:\n",
    "        # Load the trained model\n",
    "        model = load_model(os.path.join(f\"models/model_{architecture}_{optimizer_name}.h5\"))\n",
    "\n",
    "        # Make predictions on the validation dataset using the redefined val_dataset\n",
    "        y_pred = model.predict(val_dataset)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        # Get the true labels of the validation dataset\n",
    "        y_true = val_dataset.classes\n",
    "\n",
    "        # Compute the confusion matrix\n",
    "        cm = confusion_matrix(y_true, y_pred_classes)\n",
    "        print(f\"Confusion Matrix for {architecture}_{optimizer_name}:\")\n",
    "        print(cm)\n",
    "\n",
    "        # Save the confusion matrix as a CSV file\n",
    "        cm_filename = f\"confusion_matrix_{architecture}_{optimizer_name}.csv\"\n",
    "        np.savetxt(os.path.join(visualizations_dir, cm_filename), cm, delimiter=\",\")\n",
    "\n",
    "        # Compute the classification report\n",
    "        cr = classification_report(y_true, y_pred_classes, target_names=class_names)\n",
    "        print(f\"Classification Report for {architecture}_{optimizer_name}:\")\n",
    "        print(cr)\n",
    "\n",
    "        # Save the classification report as a text file\n",
    "        cr_filename = f\"classification_report_{architecture}_{optimizer_name}.txt\"\n",
    "        with open(os.path.join(visualizations_dir, cr_filename), \"w\") as file:\n",
    "            file.write(cr)\n",
    "\n",
    "        # Compute the ROC curve and AUC for each class\n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "        for i in range(len(class_names)):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_true == i, y_pred[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        # Plot the ROC curve for each class\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for i in range(len(class_names)):\n",
    "            plt.plot(\n",
    "                fpr[i],\n",
    "                tpr[i],\n",
    "                label=f\"ROC curve of class {class_names[i]} (AUC = {roc_auc[i]:.2f})\",\n",
    "            )\n",
    "        plt.plot([0, 1], [0, 1], \"k--\")\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(f\"ROC Curve for {architecture}_{optimizer_name}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(visualizations_dir, f\"roc_curve_{architecture}_{optimizer_name}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "        # Visualize the model's predictions on a subset of the validation data\n",
    "        subset_size = 10\n",
    "        subset_indices = np.random.choice(len(val_dataset), subset_size, replace=False)\n",
    "        subset_images = []\n",
    "        subset_labels = []\n",
    "        val_dataset.reset()  # Reset the validation dataset iterator\n",
    "        for i in range(len(val_dataset)):\n",
    "            if i in subset_indices:\n",
    "                image_batch, label_batch = next(val_dataset)\n",
    "                for image, label in zip(image_batch, label_batch):\n",
    "                    subset_images.append(image)\n",
    "                    subset_labels.append(label)\n",
    "\n",
    "        subset_images = np.array(subset_images)\n",
    "        subset_labels = np.array(subset_labels)\n",
    "\n",
    "        subset_preds = model.predict(subset_images)\n",
    "        subset_pred_classes = np.argmax(subset_preds, axis=1)\n",
    "\n",
    "        # Generate the visualization plot\n",
    "        plt.figure(figsize=(15, 10))\n",
    "        for i in range(subset_size):\n",
    "            plt.subplot(2, 5, i + 1)\n",
    "            plt.imshow(subset_images[i])\n",
    "            plt.title(\n",
    "                f\"True: {class_names[np.argmax(subset_labels[i])]}\\\\nPred: {class_names[subset_pred_classes[i]]}\"\n",
    "            )\n",
    "            plt.axis(\"off\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(visualizations_dir, f\"predictions_{architecture}_{optimizer_name}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "# Read the CSV file and store the model results\n",
    "model_results = []\n",
    "with open(\"model_results.csv\", \"r\") as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        model_results.append(row)\n",
    "\n",
    "# Create a bar plot for validation precision\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(model_results)), [float(result[\"precision\"]) for result in model_results])\n",
    "plt.xticks(\n",
    "    range(len(model_results)),\n",
    "    [f\"{result['architecture']}_{result['optimizer']}\" for result in model_results],\n",
    "    rotation=45,\n",
    ")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Validation Precision\")\n",
    "plt.title(\"Validation Precision for Different Models\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(visualizations_dir, \"validation_precision_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Create a bar plot for validation recall\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(model_results)), [float(result[\"recall\"]) for result in model_results])\n",
    "plt.xticks(\n",
    "    range(len(model_results)),\n",
    "    [f\"{result['architecture']}_{result['optimizer']}\" for result in model_results],\n",
    "    rotation=45,\n",
    ")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Validation Recall\")\n",
    "plt.title(\"Validation Recall for Different Models\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(visualizations_dir, \"validation_recall_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Create a bar plot for validation AUC-ROC\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(model_results)), [float(result[\"auc\"]) for result in model_results])\n",
    "plt.xticks(\n",
    "    range(len(model_results)),\n",
    "    [f\"{result['architecture']}_{result['optimizer']}\" for result in model_results],\n",
    "    rotation=45,\n",
    ")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Validation AUC-ROC\")\n",
    "plt.title(\"Validation AUC-ROC for Different Models\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(visualizations_dir, \"validation_auc_comparison.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Visualizations Outside of Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16, ResNet50, InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "import csv\n",
    "import os\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "visualizations_dir = \"visualizations\"\n",
    "\n",
    "## Read the CSV file and store the model results\n",
    "model_results = []\n",
    "with open(\"model_results.csv\", \"r\") as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    for row in csv_reader:\n",
    "        model_results.append(row)\n",
    "\n",
    "# Create a bar plot for validation precision\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(model_results)), [float(result[\"precision\"]) for result in model_results])\n",
    "plt.xticks(\n",
    "    range(len(model_results)),\n",
    "    [f\"{result['architecture']}_{result['optimizer']}\" for result in model_results],\n",
    "    rotation=45,\n",
    ")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Validation Precision\")\n",
    "plt.title(\"Validation Precision for Different Models\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(visualizations_dir, \"validation_precision_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Create a bar plot for validation recall\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(model_results)), [float(result[\"recall\"]) for result in model_results])\n",
    "plt.xticks(\n",
    "    range(len(model_results)),\n",
    "    [f\"{result['architecture']}_{result['optimizer']}\" for result in model_results],\n",
    "    rotation=45,\n",
    ")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Validation Recall\")\n",
    "plt.title(\"Validation Recall for Different Models\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(visualizations_dir, \"validation_recall_comparison.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Create a bar plot for validation AUC-ROC\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(model_results)), [float(result[\"auc\"]) for result in model_results])\n",
    "plt.xticks(\n",
    "    range(len(model_results)),\n",
    "    [f\"{result['architecture']}_{result['optimizer']}\" for result in model_results],\n",
    "    rotation=45,\n",
    ")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Validation AUC-ROC\")\n",
    "plt.title(\"Validation AUC-ROC for Different Models\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(visualizations_dir, \"validation_auc_comparison.png\"))\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
